{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb94717-76e8-43f4-a95b-25abefe9a114",
   "metadata": {},
   "source": [
    "# Download de PDFs da Melbourne Punch\n",
    "\n",
    "Este notebook demonstra como fazer download de PDFs de edições da Melbourne Punch no Trove. No entanto, abordaremos um tipo de download baseado em URLs em um arquivo \\`records.csv\\`.\n",
    "\n",
    "Esse arquivo pode ser obtivo através da ferramenta de bulk download do Trove.\n",
    "\n",
    "---\n",
    "\n",
    "Vamos começar importando as bibliotecas necessárias e configurando nosso ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a5b33-d781-449c-97bd-3acde0126c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                 \n",
    "import traceback\n",
    "from typing import (\n",
    "    List,\n",
    "    Dict,\n",
    "    Tuple,\n",
    "    Optional\n",
    ")\n",
    "import concurrent.futures     \n",
    "from datetime import datetime \n",
    "import re                    \n",
    "import pandas as pd         \n",
    "import requests      \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81244a-7896-44a8-b38a-7ee764cfa2b0",
   "metadata": {},
   "source": [
    "### 1. Configurações Iniciais e Variáveis Globais\n",
    "\n",
    "Esta seção define as principais variáveis que controlam o comportamento do script de download.\n",
    "\n",
    "Você pode ajustar esses valores para personalizar a operação de acordo com suas necessidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c3997-6ffd-4426-bcd7-71a104925c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE: str = 'newRecords.csv'\n",
    "PDF_OUTPUT_DIR: str = 'PDFs'\n",
    "NUM_DOWNLOAD_THREADS: int = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f90d6-9604-4c13-98e4-0f51487f4c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PDF_OUTPUT_DIR):\n",
    "    os.makedirs(PDF_OUTPUT_DIR)\n",
    "    print(f\"Diretório '{PDF_OUTPUT_DIR}' criado com sucesso.\")\n",
    "else:\n",
    "    print(f\"Diretório '{PDF_OUTPUT_DIR}' já existe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d47c70f-cd47-4077-be65-0dfd1a9bfb19",
   "metadata": {},
   "source": [
    "### 2. Carregamento dos Dados do Arquivo CSV\n",
    "\n",
    "Esta célula carrega os dados do arquivo CSV especificado na variável `CSV_FILE`\n",
    "e exibe uma mensagem de sucesso ou erro, dependendo do resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b28c3d9-c2a9-4646-8a50-30966818aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df: pd.DataFrame = pd.read_csv(CSV_FILE)\n",
    "    print(f\"Arquivo '{CSV_FILE}' carregado com sucesso. {len(df)} registros encontrados.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo CSV não encontrado em '{CSV_FILE}'.\")\n",
    "    print(\"Por favor, verifique o caminho e execute o notebook anterior se necessário.\")\n",
    "    raise FileNotFoundError(f\"Arquivo CSV não encontrado em '{CSV_FILE}'\")\n",
    "except Exception as e:\n",
    "    print(f\"ERRO CRÍTICO: Erro inesperado ao carregar o CSV '{CSV_FILE}'.\")\n",
    "    print(f\"Detalhes: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf637ef2-a62d-40cf-bc51-c0c406a646d6",
   "metadata": {},
   "source": [
    "### 3. Função para Download de PDFs Individuais\n",
    "\n",
    "Essa função, `download_pdf`, foi projetada para recuperar um único documento digital (especificamente, um arquivo PDF) de seu local on-line e salvá-lo em seu armazenamento local.\n",
    "\n",
    "Veja como ela funciona:\n",
    "\n",
    "1.  **Verificação de cópias existentes:** A função primeiro verifica se o documento já foi baixado e salvo. Se houver uma cópia com o mesmo nome no local especificado, a função pulará o download e informará que o arquivo existente será usado. Isso evita downloads desnecessários.\n",
    "\n",
    "2.  **Baixar o documento:** Se for necessário fazer o download do documento, nós o buscamos em seu endereço da Web. Ele também verifica se há erros durante esse processo, como o fato de o documento não ter sido encontrado no endereço fornecido.\n",
    "\n",
    "3.  **Acompanhamento do progresso do download:** Para documentos maiores, a função exibe uma barra de progresso. Esse indicador visual mostra quanto do documento foi recuperado com êxito.\n",
    "\n",
    "4.  **Salvando o documento:** Depois que o documento é totalmente baixado, a função o salva no local especificado no armazenamento do computador.\n",
    "\n",
    "5.  **Relatório do resultado:** Por fim, a função informa o resultado da operação. Ela indica se o download foi bem-sucedido, ignorado (porque o arquivo já existia) ou se ocorreu um erro. Se tiver ocorrido um erro, a função fornecerá detalhes sobre a natureza do problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a2de4-a387-4c40-8c03-546977642e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(unique_download_id: str, pdf_url: str, output_path: str) -> Dict:\n",
    "    if os.path.exists(output_path):\n",
    "        return {'unique_download_id': unique_download_id, 'status': 'skipped', 'filename': output_path, 'reason': 'already exists'}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(pdf_url, stream=True, timeout=60)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        chunk_size = 8192\n",
    "\n",
    "        progress = tqdm(total=total_size, unit='iB', unit_scale=True,\n",
    "                        desc=f'Baixando {unique_download_id}', leave=False)\n",
    "\n",
    "        with open(output_path, 'wb') as pdf_file:\n",
    "            for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "                if chunk:\n",
    "                    progress.update(len(chunk))\n",
    "                    pdf_file.write(chunk)\n",
    "                    \n",
    "        progress.close()\n",
    "\n",
    "        return {'unique_download_id': unique_download_id, 'status': 'success', 'filename': output_path}\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {'unique_download_id': unique_download_id, 'status': 'failed', 'error': f\"Erro na requisição: {e}\"}\n",
    "    except Exception as e:\n",
    "        return {'unique_download_id': unique_download_id, 'status': 'failed', 'error': f\"Erro inesperado: {e}\", 'traceback': traceback.format_exc()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941c7f13-9da8-40f9-a552-3347c5a22c2e",
   "metadata": {},
   "source": [
    "## 4: Orquestrando a recuperação em massa de documentos digitais\n",
    "\n",
    "Por fim, recuperaremos vários documentos digitais (arquivos PDF) com base na lista preparada anteriormente.\n",
    "\n",
    "Veja a seguir um detalhamento das etapas:\n",
    "\n",
    "1.  **Preparação da lista de download:** Primeiro, o sistema cria uma lista detalhada de todos os documentos que precisam ser recuperados. Para cada documento, essa lista inclui seu identificador exclusivo, seu endereço da Web (URL) e o local onde ele deve ser salvo em seu computador.\n",
    "\n",
    "2.  **Monitoramento do progresso geral:** Uma barra de progresso é exibida para fornecer uma representação visual de quantos documentos foram recuperados com êxito do número total de documentos na lista. Isso permite que você acompanhe a conclusão geral do processo de recuperação.\n",
    "\n",
    "3.  **Registro dos documentos recuperados:** À medida que cada documento é baixado com êxito (ou se foi ignorado porque já existia), o sistema mantém um registro do identificador do documento e do local salvo no seu computador.\n",
    "\n",
    "4.  **Tratamento de problemas:** Se ocorrer algum problema durante a recuperação de um documento específico (por exemplo, o endereço da Web está incorreto ou há um problema de rede), o sistema tentará relatar esses erros.\n",
    "\n",
    "5.  **Finalização do processo:** Depois que todos os documentos da lista tiverem sido processados (baixados, ignorados ou resultaram em erro), uma mensagem indicará que todo o processo de recuperação foi concluído. O sistema também o lembrará da pasta onde todos os documentos baixados com êxito podem ser encontrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d716d1-cc36-47e4-818f-78e12d03953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_filepath_map: Dict[str, str] = {}\n",
    "pdf_downloads_unique: List[Tuple[str, str, str]] = []\n",
    "item_id_to_filepaths: Dict[str, List[str]] = {}\n",
    "\n",
    "print(\"\\nPreparando lista de PDFs para download\")\n",
    "\n",
    "PAGE_ID_PATTERN = re.compile(r'nla\\.news-page(\\d+)')\n",
    "\n",
    "for row_idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Mapeando URLs de PDF\"):\n",
    "    original_item_id: str = str(row['id']) \n",
    "    pdf_url_raw: Optional[str] = row.get('trove_pdf_url')\n",
    "\n",
    "    if pd.notna(pdf_url_raw):\n",
    "        potential_urls: List[str] = str(pdf_url_raw).split('|')\n",
    "\n",
    "        for url_idx, url in enumerate(potential_urls):\n",
    "            cleaned_url = url.strip()\n",
    "            \n",
    "            if cleaned_url.startswith('http') and len(cleaned_url) > 10:\n",
    "                pdf_filename_base = \"\"\n",
    "                unique_download_id = \"\"\n",
    "                \n",
    "                match = PAGE_ID_PATTERN.search(cleaned_url)\n",
    "                if match:\n",
    "                    page_id = match.group(1)\n",
    "                    pdf_filename_base = f\"{page_id}.pdf\"\n",
    "                    unique_download_id = page_id\n",
    "                else:\n",
    "                    pdf_filename_base = f\"{original_item_id}_{url_idx+1}.pdf\"\n",
    "                    unique_download_id = f\"{original_item_id}_{url_idx+1}\"\n",
    "                    print(f\"Formato de URL Trove inesperado para ID {original_item_id} (URL: '{cleaned_url}'). Usando nome de arquivo padrão: '{pdf_filename_base}'\")\n",
    "\n",
    "                output_path = os.path.join(PDF_OUTPUT_DIR, pdf_filename_base)\n",
    "                \n",
    "                if cleaned_url not in url_to_filepath_map:\n",
    "                    url_to_filepath_map[cleaned_url] = output_path\n",
    "                    pdf_downloads_unique.append((unique_download_id, cleaned_url, output_path))\n",
    "                    print(f\"Adicionado download único: {pdf_filename_base} da URL: {cleaned_url}\")\n",
    "                else:\n",
    "                    print(f\"URL '{cleaned_url}' já enfileirada para download como '{url_to_filepath_map[cleaned_url]}'.\")\n",
    "                \n",
    "                if original_item_id not in item_id_to_filepaths:\n",
    "                    item_id_to_filepaths[original_item_id] = []\n",
    "\n",
    "                item_id_to_filepaths[original_item_id].append(output_path)\n",
    "\n",
    "            else:\n",
    "                print(f\"URL de PDF inválida ou malformada detectada para ID original {original_item_id} (URL {url_idx+1}): '{url}'. Ignorando.\")\n",
    "    else:\n",
    "        print(f\"PDF URL ausente ou NaN para ID original {original_item_id}. Nenhuma URL encontrada para download.\")\n",
    "\n",
    "print(f\"\\nTotal de {len(pdf_downloads_unique)} PDFs ÚNICOS elegíveis para download (após desduplicação de URLs).\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(f\"Finalizada preparação. Total de {len(pdf_downloads_unique)} PDFs únicos para processar.\")\n",
    "\n",
    "downloaded_files_status: Dict[str, str] = {}\n",
    "failed_downloads_list: List[Dict] = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=NUM_DOWNLOAD_THREADS) as executor:\n",
    "    futures = {\n",
    "        executor.submit(download_pdf, unique_id, pdf_url, output_path): unique_id\n",
    "        for unique_id, pdf_url, output_path in pdf_downloads_unique\n",
    "    }\n",
    "    \n",
    "    for future in tqdm(concurrent.futures.as_completed(futures),\n",
    "                       total=len(futures),\n",
    "                       desc=\"Progresso Geral do Download de PDFs\"):\n",
    "        unique_id = futures[future]\n",
    "        try:\n",
    "            result: Dict = future.result()  \n",
    "\n",
    "            if result['status'] == 'success' or result['status'] == 'skipped':\n",
    "                downloaded_files_status[result['unique_download_id']] = result['filename']\n",
    "            else: \n",
    "                failed_downloads_list.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro inesperado ao processar resultado para ID de download {unique_id}: {e}\\n{traceback.format_exc()}\")\n",
    "            failed_downloads_list.append({'unique_download_id': unique_id, 'status': 'failed', 'error': f\"Erro de processamento: {e}\", 'traceback': traceback.format_exc()})\n",
    "\n",
    "print(\"\\n--- Processo de Download de PDFs Concluído ---\")\n",
    "print(f\"Total de downloads únicos considerados: {len(pdf_downloads_unique)}\")\n",
    "\n",
    "successful_downloads_count = 0\n",
    "skipped_downloads_count = 0\n",
    "\n",
    "for future in futures:\n",
    "    if future.done():\n",
    "        try:\n",
    "            result = future.result()\n",
    "            if result['status'] == 'success':\n",
    "                successful_downloads_count += 1\n",
    "            elif result['status'] == 'skipped':\n",
    "                skipped_downloads_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao obter resultado de um future para contagem final: {e}\")\n",
    "\n",
    "\n",
    "print(f\"PDFs baixados com sucesso (novos): {successful_downloads_count}\")\n",
    "print(f\"PDFs pulados (já existiam): {skipped_downloads_count}\")\n",
    "print(f\"PDFs com falha no download: {len(failed_downloads_list)}\")\n",
    "print(f\"Todos os PDFs baixados estão em: '{os.path.abspath(PDF_OUTPUT_DIR)}'\")\n",
    "\n",
    "if failed_downloads_list:\n",
    "    print(\"\\n--- DETALHES DOS DOWNLOADS FALHOS: ---\")\n",
    "    for failure in failed_downloads_list:\n",
    "        print(f\"  ID de Download: {failure.get('unique_download_id', 'N/A')}\")\n",
    "        print(f\"  Erro: {failure.get('error', 'N/A')}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "print(\"\\nAnálise completa. Você pode verificar a pasta de saída para os arquivos PDF.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374992e-f8da-436f-a93a-ae48402c616c",
   "metadata": {},
   "source": [
    "### 5. Atualizando o DataFrame com os Nomes dos Arquivos Baixados\n",
    "\n",
    "Agora, vamos adicionar uma nova coluna ao nosso DataFrame original (`df`) que registrará os nomes dos arquivos PDF que foram baixados ou já existiam para cada entrada. \n",
    "\n",
    "Isso permite uma rastreabilidade fácil entre seus dados e os arquivos físicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be96e0-e7bb-4e67-822c-63bb8015e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['downloaded_pdf_filenames'] = df['id'].apply(lambda x: item_id_to_filepaths.get(str(x), []))\n",
    "\n",
    "selected_columns = ['id', 'trove_page_url', 'date', 'page', 'illustrated', 'type', 'downloaded_pdf_filenames']\n",
    "\n",
    "try:\n",
    "    df_selected = df[selected_columns]\n",
    "    new_csv_filename = 'selected_records_with_downloaded_pdfs.csv'\n",
    "    df_selected.to_csv(new_csv_filename, index=False)\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(f\"\\nATENÇÃO: Uma das colunas selecionadas não foi encontrada no DataFrame original: {e}.\")\n",
    "    print(\"Por favor, verifique se todas as colunas existem antes de tentar selecioná-las.\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
